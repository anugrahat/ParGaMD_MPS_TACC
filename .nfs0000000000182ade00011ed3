WARNING: CPU IP/backtrace sampling not supported, disabling.
Try the 'nsys status --environment' command to learn more.

WARNING: CPU context switch tracing not supported, disabling.
Try the 'nsys status --environment' command to learn more.

Agent launcher failed.
+ cd /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2
+ echo 'Initially, CUDA_VISIBLE_DEVICES=0,1'
Initially, CUDA_VISIBLE_DEVICES=0,1
+ nvidia-smi -L
GPU 0: NVIDIA A100-SXM4-80GB (UUID: GPU-eeac6e0f-e2b3-f79b-d3df-805ea61f14d7)
GPU 1: NVIDIA A100-SXM4-80GB (UUID: GPU-b7b4c9bc-a6b0-8bd2-075e-e3d9f299f47f)
+ source env.sh
++ source /home/anugraha/.bashrc
+++ i
/home/anugraha/.bashrc: line 1: i: command not found
++++ /software/anaconda3/2020.11/ucdhpc-20.04/bin/conda shell.bash hook
+++ __conda_setup='export CONDA_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause

__add_sys_prefix_to_path() {
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA}" ] && [ -n "${WINDIR+x}" ]; then
        SYSP=$(\dirname "${CONDA_EXE}")
    else
        SYSP=$(\dirname "${CONDA_EXE}")
        SYSP=$(\dirname "${SYSP}")
    fi

    if [ -n "${WINDIR+x}" ]; then
        PATH="${SYSP}/bin:${PATH}"
        PATH="${SYSP}/Scripts:${PATH}"
        PATH="${SYSP}/Library/bin:${PATH}"
        PATH="${SYSP}/Library/usr/bin:${PATH}"
        PATH="${SYSP}/Library/mingw-w64/bin:${PATH}"
        PATH="${SYSP}:${PATH}"
    else
        PATH="${SYSP}/bin:${PATH}"
    fi
    \export PATH
}

__conda_exe() (
    __add_sys_prefix_to_path
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
+++ '[' 0 -eq 0 ']'
+++ eval 'export CONDA_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause

__add_sys_prefix_to_path() {
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA}" ] && [ -n "${WINDIR+x}" ]; then
        SYSP=$(\dirname "${CONDA_EXE}")
    else
        SYSP=$(\dirname "${CONDA_EXE}")
        SYSP=$(\dirname "${SYSP}")
    fi

    if [ -n "${WINDIR+x}" ]; then
        PATH="${SYSP}/bin:${PATH}"
        PATH="${SYSP}/Scripts:${PATH}"
        PATH="${SYSP}/Library/bin:${PATH}"
        PATH="${SYSP}/Library/usr/bin:${PATH}"
        PATH="${SYSP}/Library/mingw-w64/bin:${PATH}"
        PATH="${SYSP}:${PATH}"
    else
        PATH="${SYSP}/bin:${PATH}"
    fi
    \export PATH
}

__conda_exe() (
    __add_sys_prefix_to_path
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
++++ export CONDA_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
++++ CONDA_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
++++ export _CE_M=
++++ _CE_M=
++++ export _CE_CONDA=
++++ _CE_CONDA=
++++ export CONDA_PYTHON_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/python
++++ CONDA_PYTHON_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/python
++++ '[' -z x ']'
++++ conda activate base
++++ local cmd=activate
++++ case "$cmd" in
++++ __conda_activate activate base
++++ '[' -n '' ']'
++++ local ask_conda
+++++ PS1='(openmm_env) '
+++++ __conda_exe shell.posix activate base
+++++ __add_sys_prefix_to_path
+++++ '[' -n '' ']'
++++++ dirname /software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
+++++ SYSP=/software/anaconda3/2020.11/ucdhpc-20.04/bin
++++++ dirname /software/anaconda3/2020.11/ucdhpc-20.04/bin
+++++ SYSP=/software/anaconda3/2020.11/ucdhpc-20.04
+++++ '[' -n '' ']'
+++++ PATH=/software/anaconda3/2020.11/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/home/anugraha/.conda/envs/openmm_env/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin
+++++ export PATH
+++++ /software/anaconda3/2020.11/ucdhpc-20.04/bin/conda shell.posix activate base
++++ ask_conda='. "/home/anugraha/.conda/envs/openmm_env/etc/conda/deactivate.d/libglib_deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/software/modules/4.6.1/ucdhpc-20.04/bin:/software/anaconda3/2020.11/ucdhpc-20.04/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin'\''
export CONDA_PREFIX='\''/software/anaconda3/2020.11/ucdhpc-20.04'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/python'\''
export CONDA_PREFIX_1='\''/home/anugraha/.conda/envs/openmm_env'\'''
++++ eval '. "/home/anugraha/.conda/envs/openmm_env/etc/conda/deactivate.d/libglib_deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/software/modules/4.6.1/ucdhpc-20.04/bin:/software/anaconda3/2020.11/ucdhpc-20.04/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin'\''
export CONDA_PREFIX='\''/software/anaconda3/2020.11/ucdhpc-20.04'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/python'\''
export CONDA_PREFIX_1='\''/home/anugraha/.conda/envs/openmm_env'\'''
+++++ . /home/anugraha/.conda/envs/openmm_env/etc/conda/deactivate.d/libglib_deactivate.sh
++++++ export GSETTINGS_SCHEMA_DIR=
++++++ GSETTINGS_SCHEMA_DIR=
++++++ unset GSETTINGS_SCHEMA_DIR_CONDA_BACKUP
++++++ '[' -z ']'
++++++ unset GSETTINGS_SCHEMA_DIR
+++++ PS1='(base) '
+++++ export PATH=/software/modules/4.6.1/ucdhpc-20.04/bin:/software/anaconda3/2020.11/ucdhpc-20.04/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin
+++++ PATH=/software/modules/4.6.1/ucdhpc-20.04/bin:/software/anaconda3/2020.11/ucdhpc-20.04/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin
+++++ export CONDA_PREFIX=/software/anaconda3/2020.11/ucdhpc-20.04
+++++ CONDA_PREFIX=/software/anaconda3/2020.11/ucdhpc-20.04
+++++ export CONDA_SHLVL=2
+++++ CONDA_SHLVL=2
+++++ export CONDA_DEFAULT_ENV=base
+++++ CONDA_DEFAULT_ENV=base
+++++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++++ CONDA_PROMPT_MODIFIER='(base) '
+++++ export CONDA_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
+++++ CONDA_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
+++++ export _CE_M=
+++++ _CE_M=
+++++ export _CE_CONDA=
+++++ _CE_CONDA=
+++++ export CONDA_PYTHON_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/python
+++++ CONDA_PYTHON_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/python
+++++ export CONDA_PREFIX_1=/home/anugraha/.conda/envs/openmm_env
+++++ CONDA_PREFIX_1=/home/anugraha/.conda/envs/openmm_env
++++ __conda_hashr
++++ '[' -n '' ']'
++++ '[' -n '' ']'
++++ hash -r
+++ unset __conda_setup
+++ git config --global user.email anuthyagatur@ucdavis.edu
+++ export PATH=/software/modules/4.6.1/ucdhpc-20.04/bin:/software/anaconda3/2020.11/ucdhpc-20.04/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin:/home/anugraha/.conda/envs/myenv/bin
+++ PATH=/software/modules/4.6.1/ucdhpc-20.04/bin:/software/anaconda3/2020.11/ucdhpc-20.04/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin:/home/anugraha/.conda/envs/myenv/bin
++ module load conda3/4.X cuda/11.8.0
++ unset _mlshdbg
++ '[' 0 = 1 ']'
++ unset _mlre _mlIFS
++ '[' -n x ']'
++ _mlIFS=' 	
'
++ IFS=' '
++ '[' -n '' ']'
+++ /usr/bin/tclsh /software/modules/4.6.1/ucdhpc-20.04/libexec/modulecmd.tcl bash load conda3/4.X cuda/11.8.0
++ eval
++ _mlstatus=0
++ '[' -n x ']'
++ IFS=' 	
'
++ unset _mlre _mlv _mlrv _mlIFS
++ '[' -n '' ']'
++ unset _mlshdbg
++ return 0
++ source activate openmm_env
+++ _CONDA_ROOT=/software/anaconda3/2020.11/ucdhpc-20.04
+++ . /software/anaconda3/2020.11/ucdhpc-20.04/etc/profile.d/conda.sh
++++ export CONDA_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
++++ CONDA_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
++++ export _CE_M=
++++ _CE_M=
++++ export _CE_CONDA=
++++ _CE_CONDA=
++++ export CONDA_PYTHON_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/python
++++ CONDA_PYTHON_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/python
++++ '[' -z x ']'
+++ conda activate openmm_env
+++ local cmd=activate
+++ case "$cmd" in
+++ __conda_activate activate openmm_env
+++ '[' -n '' ']'
+++ local ask_conda
++++ PS1='(base) '
++++ __conda_exe shell.posix activate openmm_env
++++ __add_sys_prefix_to_path
++++ '[' -n '' ']'
+++++ dirname /software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
++++ SYSP=/software/anaconda3/2020.11/ucdhpc-20.04/bin
+++++ dirname /software/anaconda3/2020.11/ucdhpc-20.04/bin
++++ SYSP=/software/anaconda3/2020.11/ucdhpc-20.04
++++ '[' -n '' ']'
++++ PATH=/software/anaconda3/2020.11/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/software/anaconda3/2020.11/ucdhpc-20.04/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin:/home/anugraha/.conda/envs/myenv/bin
++++ export PATH
++++ /software/anaconda3/2020.11/ucdhpc-20.04/bin/conda shell.posix activate openmm_env
+++ ask_conda='export PATH='\''/software/modules/4.6.1/ucdhpc-20.04/bin:/home/anugraha/.conda/envs/openmm_env/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin:/home/anugraha/.conda/envs/myenv/bin'\''
unset CONDA_PREFIX_1
PS1='\''(openmm_env) '\''
export CONDA_PREFIX='\''/home/anugraha/.conda/envs/openmm_env'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''openmm_env'\''
export CONDA_PROMPT_MODIFIER='\''(openmm_env) '\''
export CONDA_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/python'\''
. "/home/anugraha/.conda/envs/openmm_env/etc/conda/activate.d/libglib_activate.sh"'
+++ eval 'export PATH='\''/software/modules/4.6.1/ucdhpc-20.04/bin:/home/anugraha/.conda/envs/openmm_env/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin:/home/anugraha/.conda/envs/myenv/bin'\''
unset CONDA_PREFIX_1
PS1='\''(openmm_env) '\''
export CONDA_PREFIX='\''/home/anugraha/.conda/envs/openmm_env'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''openmm_env'\''
export CONDA_PROMPT_MODIFIER='\''(openmm_env) '\''
export CONDA_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/software/anaconda3/2020.11/ucdhpc-20.04/bin/python'\''
. "/home/anugraha/.conda/envs/openmm_env/etc/conda/activate.d/libglib_activate.sh"'
++++ export PATH=/software/modules/4.6.1/ucdhpc-20.04/bin:/home/anugraha/.conda/envs/openmm_env/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin:/home/anugraha/.conda/envs/myenv/bin
++++ PATH=/software/modules/4.6.1/ucdhpc-20.04/bin:/home/anugraha/.conda/envs/openmm_env/bin:/software/conda3/4.X/condabin:/software/conda3/4.X/bin:/software/openmpi/4.1.5/ucdhpc-20.04/bin:/software/hwloc/2.9.3/ucdhpc-20.04/bin:/software/slurm/23.02.7/ucdhpc-20.04/sbin:/software/slurm/23.02.7/ucdhpc-20.04/bin:/software/cuda/11.8.0/ucdhpc-20.04/bin:/software/modules/4.6.1/ucdhpc-20.04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/opt/puppetlabs/bin:/home/anugraha/.conda/envs/myenv/bin
++++ unset CONDA_PREFIX_1
++++ PS1='(openmm_env) '
++++ export CONDA_PREFIX=/home/anugraha/.conda/envs/openmm_env
++++ CONDA_PREFIX=/home/anugraha/.conda/envs/openmm_env
++++ export CONDA_SHLVL=1
++++ CONDA_SHLVL=1
++++ export CONDA_DEFAULT_ENV=openmm_env
++++ CONDA_DEFAULT_ENV=openmm_env
++++ export 'CONDA_PROMPT_MODIFIER=(openmm_env) '
++++ CONDA_PROMPT_MODIFIER='(openmm_env) '
++++ export CONDA_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
++++ CONDA_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/conda
++++ export _CE_M=
++++ _CE_M=
++++ export _CE_CONDA=
++++ _CE_CONDA=
++++ export CONDA_PYTHON_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/python
++++ CONDA_PYTHON_EXE=/software/anaconda3/2020.11/ucdhpc-20.04/bin/python
++++ . /home/anugraha/.conda/envs/openmm_env/etc/conda/activate.d/libglib_activate.sh
+++++ export GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
+++++ GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
+++++ export GSETTINGS_SCHEMA_DIR=/home/anugraha/.conda/envs/openmm_env/share/glib-2.0/schemas
+++++ GSETTINGS_SCHEMA_DIR=/home/anugraha/.conda/envs/openmm_env/share/glib-2.0/schemas
+++ __conda_hashr
+++ '[' -n '' ']'
+++ '[' -n '' ']'
+++ hash -r
++ [[ -z '' ]]
++ export WEST_SIM_ROOT=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2
++ WEST_SIM_ROOT=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2
+++ basename /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2
++ export SIM_NAME=ParGaMD_chig_2
++ SIM_NAME=ParGaMD_chig_2
++ echo 'simulation ParGaMD_chig_2 root is /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2'
simulation ParGaMD_chig_2 root is /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2
++ export USE_LOCAL_SCRATCH=1
++ USE_LOCAL_SCRATCH=1
++ export WM_ZMQ_MASTER_HEARTBEAT=100
++ WM_ZMQ_MASTER_HEARTBEAT=100
++ export WM_ZMQ_WORKER_HEARTBEAT=100
++ WM_ZMQ_WORKER_HEARTBEAT=100
++ export WM_ZMQ_TIMEOUT_FACTOR=300
++ WM_ZMQ_TIMEOUT_FACTOR=300
+ export SERVER_INFO=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json
+ SERVER_INFO=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json
+ export WM_ZMQ_MASTER_HEARTBEAT=50
+ WM_ZMQ_MASTER_HEARTBEAT=50
+ export WM_ZMQ_WORKER_HEARTBEAT=50
+ WM_ZMQ_WORKER_HEARTBEAT=50
+ export WM_ZMQ_TIMEOUT_FACTOR=100
+ WM_ZMQ_TIMEOUT_FACTOR=100
+ (( n=0 ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ w_run --work-manager=zmq --n-workers=0 --zmq-mode=master --zmq-write-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ sleep 1
+ (( n++ ))
+ (( n<60 ))
+ '[' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ cat /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json
{"rr_endpoint": "tcp://sapphire-0:60349", "ann_endpoint": "tcp://sapphire-0:50743"}+ break
+ '[' '!' -e /home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json ']'
+ SM_LOG=gpu_dmon_682944.log
+ echo 'Logging SM usage to gpu_dmon_682944.log (every 10s)'
Logging SM usage to gpu_dmon_682944.log (every 10s)
+ DMON_PID=618657
+ MEM_LOG=gpu_query_682944.log
+ echo 'Logging memory/overall usage to gpu_query_682944.log (every 10s)'
Logging memory/overall usage to gpu_query_682944.log (every 10s)
+ nvidia-smi dmon -s u -d 10
+ QPID=618658
+ export WORKERS_PER_GPU=12
+ WORKERS_PER_GPU=12
+ IFS=,
+ read -ra DEVICES
+ nvidia-smi --query-gpu=timestamp,index,name,utilization.gpu,utilization.memory,memory.total,memory.used --format=csv -l 10
+ total_workers=24
+ echo 'Debug: DEVICES = 0' 1
Debug: DEVICES = 0 1
+ echo 'Debug: total_workers = 24'
Debug: total_workers = 24
+ for gpuid in "${DEVICES[@]}"
+ (( w=1 ))
+ (( w<=WORKERS_PER_GPU ))
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ (( w++ ))
+ export CUDA_VISIBLE_DEVICES=0
+ (( w<=WORKERS_PER_GPU ))
+ CUDA_VISIBLE_DEVICES=0
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ (( w++ ))
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w<=WORKERS_PER_GPU ))
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ (( w++ ))
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ (( w++ ))
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ (( w<=WORKERS_PER_GPU ))
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ for gpuid in "${DEVICES[@]}"
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w=1 ))
+ (( w<=WORKERS_PER_GPU ))
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=1
+ CUDA_VISIBLE_DEVICES=1
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=1
+ CUDA_VISIBLE_DEVICES=1
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=1
+ CUDA_VISIBLE_DEVICES=1
+ (( w++ ))
+ export CUDA_VISIBLE_DEVICES=1
+ (( w<=WORKERS_PER_GPU ))
+ CUDA_VISIBLE_DEVICES=1
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=1
+ (( w++ ))
+ CUDA_VISIBLE_DEVICES=1
+ export CUDA_VISIBLE_DEVICES=1
+ (( w<=WORKERS_PER_GPU ))
+ CUDA_VISIBLE_DEVICES=1
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ export CUDA_VISIBLE_DEVICES=1
+ (( w<=WORKERS_PER_GPU ))
+ CUDA_VISIBLE_DEVICES=1
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ export CUDA_VISIBLE_DEVICES=1
+ (( w<=WORKERS_PER_GPU ))
+ CUDA_VISIBLE_DEVICES=1
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ export CUDA_VISIBLE_DEVICES=1
+ (( w<=WORKERS_PER_GPU ))
+ CUDA_VISIBLE_DEVICES=1
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=1
+ CUDA_VISIBLE_DEVICES=1
+ (( w++ ))
+ export CUDA_VISIBLE_DEVICES=1
+ CUDA_VISIBLE_DEVICES=1
+ (( w<=WORKERS_PER_GPU ))
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
+ (( w++ ))
+ (( w<=WORKERS_PER_GPU ))
+ export CUDA_VISIBLE_DEVICES=1
+ CUDA_VISIBLE_DEVICES=1
+ wait
+ w_run --work-manager=zmq --n-workers=1 --zmq-mode=client --zmq-read-host-info=/home/anugraha/openmm_GaMD_anu_psc/ParGaMD_chig_2/west_zmq_info.json --zmq-comm-mode=tcp
slurmstepd: error: *** JOB 682944 ON sapphire-0 CANCELLED AT 2025-03-08T01:51:12 ***
